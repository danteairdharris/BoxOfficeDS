{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f77a7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\anaconda\\lib\\site-packages (2.25.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\anaconda\\lib\\site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda\\lib\\site-packages (from requests) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\anaconda\\lib\\site-packages (from requests) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\anaconda\\lib\\site-packages (from requests) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a7fcd9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import requests\n",
    "import pickle\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5019c010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "https://en.wikipedia.org/wiki/Harry_Potter_and_the_Philosopher%27s_Stone_(film)\n",
      "'NoneType' object is not subscriptable\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "https://en.wikipedia.org/wiki/The_Dukes_of_Hazzard_(film)\n",
      "'NoneType' object is not subscriptable\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "https://en.wikipedia.orghttps://nl.wikipedia.org/wiki/Morrison_krijgt_een_zusje\n",
      "HTTPSConnectionPool(host='en.wikipedia.orghttps', port=443): Max retries exceeded with url: //nl.wikipedia.org/wiki/Morrison_krijgt_een_zusje (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000023FC3150F70>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "https://en.wikipedia.orghttps://nl.wikipedia.org/wiki/Hoe_overleef_ik_mezelf%3F_(film)\n",
      "HTTPSConnectionPool(host='en.wikipedia.orghttps', port=443): Max retries exceeded with url: //nl.wikipedia.org/wiki/Hoe_overleef_ik_mezelf%3F_(film) (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000023FC131B880>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "0\n",
      "10\n",
      "https://en.wikipedia.org/wiki/The_Losers_(film)\n",
      "'NoneType' object is not subscriptable\n",
      "20\n",
      "https://en.wikipedia.org/wiki/Ramayana:_The_Epic\n",
      "'NoneType' object is not subscriptable\n",
      "30\n",
      "https://en.wikipedia.orghttps://it.wikipedia.org/wiki/La_bellezza_del_somaro\n",
      "HTTPSConnectionPool(host='en.wikipedia.orghttps', port=443): Max retries exceeded with url: //it.wikipedia.org/wiki/La_bellezza_del_somaro (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000023FC38DA2E0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "40\n",
      "https://en.wikipedia.orghttps://pl.wikipedia.org/wiki/Jak_si%C4%99_pozby%C4%87_cellulitu\n",
      "HTTPSConnectionPool(host='en.wikipedia.orghttps', port=443): Max retries exceeded with url: //pl.wikipedia.org/wiki/Jak_si%C4%99_pozby%C4%87_cellulitu (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000023FC3013F70>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "https://en.wikipedia.orghttps://tr.wikipedia.org/wiki/Hayat_Sana_G%C3%BCzel_(film,_2014)\n",
      "HTTPSConnectionPool(host='en.wikipedia.orghttps', port=443): Max retries exceeded with url: //tr.wikipedia.org/wiki/Hayat_Sana_G%C3%BCzel_(film,_2014) (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000023FC36F0760>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "150\n",
      "https://en.wikipedia.orghttps://tr.wikipedia.org/wiki/Dabbe:_Zehr-i_Cin\n",
      "HTTPSConnectionPool(host='en.wikipedia.orghttps', port=443): Max retries exceeded with url: //tr.wikipedia.org/wiki/Dabbe:_Zehr-i_Cin (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000023FC4237E80>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "160\n",
      "https://en.wikipedia.org/wiki/Mortadelo_and_Filemon:_Mission_Implausible\n",
      "'NoneType' object is not subscriptable\n",
      "https://en.wikipedia.orghttps://tr.wikipedia.org/wiki/K%C4%B1r%C4%B1ml%C4%B1_(film)\n",
      "HTTPSConnectionPool(host='en.wikipedia.orghttps', port=443): Max retries exceeded with url: //tr.wikipedia.org/wiki/K%C4%B1r%C4%B1ml%C4%B1_(film) (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000023FC37847F0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "170\n",
      "https://en.wikipedia.orghttps://tr.wikipedia.org/wiki/Yusuf_Yusuf_(film)\n",
      "HTTPSConnectionPool(host='en.wikipedia.orghttps', port=443): Max retries exceeded with url: //tr.wikipedia.org/wiki/Yusuf_Yusuf_(film) (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000023FC45E8D30>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "https://en.wikipedia.orghttps://tr.wikipedia.org/wiki/Yusuf_Yusuf_(film)\n",
      "'NoneType' object is not subscriptable\n",
      "https://en.wikipedia.orghttps://tr.wikipedia.org/wiki/K%C3%B6stebekgiller:_Perili_Orman\n",
      "HTTPSConnectionPool(host='en.wikipedia.orghttps', port=443): Max retries exceeded with url: //tr.wikipedia.org/wiki/K%C3%B6stebekgiller:_Perili_Orman (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000023FC45E8D90>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "https://en.wikipedia.orghttps://tr.wikipedia.org/wiki/Sevimli_Tehlikeli\n",
      "HTTPSConnectionPool(host='en.wikipedia.orghttps', port=443): Max retries exceeded with url: //tr.wikipedia.org/wiki/Sevimli_Tehlikeli (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000023FC45E8DF0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "https://en.wikipedia.orghttps://tr.wikipedia.org/wiki/8_Saniye\n",
      "HTTPSConnectionPool(host='en.wikipedia.orghttps', port=443): Max retries exceeded with url: //tr.wikipedia.org/wiki/8_Saniye (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000023FC1E73880>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "180\n",
      "https://en.wikipedia.org/wiki/Lost_River_(film)\n",
      "'NoneType' object is not subscriptable\n",
      "190\n",
      "200\n",
      "https://en.wikipedia.orghttps://tr.wikipedia.org/wiki/Git_Ba%C5%9F%C4%B1mdan\n",
      "HTTPSConnectionPool(host='en.wikipedia.orghttps', port=443): Max retries exceeded with url: //tr.wikipedia.org/wiki/Git_Ba%C5%9F%C4%B1mdan (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000023FC20F26A0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "210\n",
      "https://en.wikipedia.orghttps://tr.wikipedia.org/wiki/Delibal\n",
      "HTTPSConnectionPool(host='en.wikipedia.orghttps', port=443): Max retries exceeded with url: //tr.wikipedia.org/wiki/Delibal (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000023FC34CAB20>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "https://en.wikipedia.orghttps://tr.wikipedia.org/wiki/K%C3%B6stebekgiller_2:_G%C3%B6lgenin_T%C4%B1ls%C4%B1m%C4%B1\n",
      "HTTPSConnectionPool(host='en.wikipedia.orghttps', port=443): Max retries exceeded with url: //tr.wikipedia.org/wiki/K%C3%B6stebekgiller_2:_G%C3%B6lgenin_T%C4%B1ls%C4%B1m%C4%B1 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000023FC34CA7F0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "https://en.wikipedia.orghttps://tr.wikipedia.org/wiki/Her_%C5%9Eey_A%C5%9Fktan_(film)\n",
      "HTTPSConnectionPool(host='en.wikipedia.orghttps', port=443): Max retries exceeded with url: //tr.wikipedia.org/wiki/Her_%C5%9Eey_A%C5%9Fktan_(film) (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000023FC34CAEB0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "https://en.wikipedia.orghttps://tr.wikipedia.org/wiki/Osman_Pazarlama\n",
      "HTTPSConnectionPool(host='en.wikipedia.orghttps', port=443): Max retries exceeded with url: //tr.wikipedia.org/wiki/Osman_Pazarlama (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000023FC3BF27F0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "220\n",
      "https://en.wikipedia.org/wiki/Midnight_Special_(film)\n",
      "'NoneType' object is not subscriptable\n",
      "230\n",
      "240\n",
      "https://en.wikipedia.orghttps://tr.wikipedia.org/wiki/Can%C4%B1m_Karde%C5%9Fim_Benim\n",
      "HTTPSConnectionPool(host='en.wikipedia.orghttps', port=443): Max retries exceeded with url: //tr.wikipedia.org/wiki/Can%C4%B1m_Karde%C5%9Fim_Benim (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000023FC1AB3400>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "https://en.wikipedia.org/wiki/May_God_Save_Us\n",
      "'NoneType' object is not subscriptable\n",
      "250\n",
      "260\n",
      "https://en.wikipedia.orghttps://tr.wikipedia.org/wiki/K%C4%B1r%C4%B1k_Kalpler_Bankas%C4%B1\n",
      "HTTPSConnectionPool(host='en.wikipedia.orghttps', port=443): Max retries exceeded with url: //tr.wikipedia.org/wiki/K%C4%B1r%C4%B1k_Kalpler_Bankas%C4%B1 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000023FC2CEB760>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "https://en.wikipedia.org/w/index.php?title=Kabir_Azab%C4%B1&action=edit&redlink=1\n",
      "'NoneType' object has no attribute 'find_all'\n",
      "310\n",
      "320\n",
      "330\n",
      "https://en.wikipedia.org/wiki/Western_Stars#Film\n",
      "'NoneType' object has no attribute 'find_all'\n",
      "340\n"
     ]
    }
   ],
   "source": [
    "## Save list_movie_data in with pickle\n",
    "def save_data(filename, data):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "## Load pickle file data \n",
    "def load_data(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "#function for scraping infobox\n",
    "def scrape(url):\n",
    "    page = requests.get(url)\n",
    "    toScrape = bs(page.content, 'html.parser')\n",
    "    movie_details = toScrape.find(class_='infobox vevent')\n",
    "    rows = movie_details.find_all('tr') \n",
    "    movie_data = {}\n",
    "\n",
    "    movie_data['Title'] = rows[0].find('th').get_text()\n",
    "    clean_tags(movie_details)\n",
    "    for i, row in enumerate(rows):\n",
    "        try:\n",
    "            if i <= 1:\n",
    "                continue\n",
    "            elif row.find('th').get_text() == 'Based on':\n",
    "                continue\n",
    "            elif row.find('th').get_text() == 'Running time':\n",
    "                movie_data['Running time (min)'] = clean(row)\n",
    "            elif row.find('th').get_text() == 'Release date':\n",
    "                date = clean(row)\n",
    "                movie_data['Release date'] = date\n",
    "                movie_data['Release date (dt)'] = dt_conversion(date)\n",
    "            else:\n",
    "                column = row.find('th').get_text(' ', strip=True)\n",
    "                data = clean(row)\n",
    "                movie_data[column] = data\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    return movie_data\n",
    "\n",
    "#Convert date str to datetime object\n",
    "def dt_conversion(date):\n",
    "    patterns = ['%B %d, %Y', '%d %B %Y']\n",
    "    for pat in patterns:\n",
    "        try:\n",
    "            return datetime.strptime(date, pat)\n",
    "        except:\n",
    "            pass\n",
    "    return None\n",
    "\n",
    "#remove troublesome tags\n",
    "def clean_tags(content):\n",
    "    t = ['sup', 'span']\n",
    "    tags = content.find_all(t)\n",
    "    for tag in tags:\n",
    "        tag.decompose()\n",
    "\n",
    "#function to clean data scraped from wikipedia infobox\n",
    "def clean(row):\n",
    "    if row.find('th').get_text() == 'Release date':\n",
    "        return row.find('td').get_text().split('(')[0].replace('\\xa0', ' ').strip('\\n').strip(' ')                                                                                         \n",
    "    elif row.find('th').get_text() == 'Running time':\n",
    "        return int(row.find('td').get_text().split(' ')[0])\n",
    "    elif row.find('br'):\n",
    "        return [text for text in row.find('td').stripped_strings]\n",
    "    elif row.find('li'):\n",
    "        return [li.get_text(' ', strip=True).replace('\\xa0', ' ') for li in row.find_all('li')]\n",
    "    else:\n",
    "        if '$' in row.find('td').get_text():\n",
    "            if 'million' in row.find('td').get_text():\n",
    "                if '-' in row.find('td').get_text():\n",
    "                    number = float(row.find('td').get_text().split('-')[0].replace('$',''))\n",
    "                else:\n",
    "                    number = float(row.find('td').get_text().split(' ')[0].replace('$',''))\n",
    "                money = number * (10**6)\n",
    "                return money\n",
    "            elif 'billion' in row.find('td').get_text():\n",
    "                if '-' in row.find('td').get_text():\n",
    "                    number = float(row.find('td').get_text().split('-')[0].replace('$',''))\n",
    "                else:\n",
    "                    number = float(row.find('td').get_text().split(' ')[0].replace('$',''))\n",
    "                money = number * (10**9)\n",
    "                return money\n",
    "    return row.find('td').get_text()\n",
    "\n",
    "# load in table of WBMovies \n",
    "# https://en.wikipedia.org/wiki/List_of_Warner_Bros._films_(2000%E2%80%932009)\n",
    "# https://en.wikipedia.org/wiki/List_of_Warner_Bros._films_(2010%E2%80%932019)\n",
    "links = ['https://en.wikipedia.org/wiki/List_of_Warner_Bros._films_(2000%E2%80%932009)', \n",
    "         'https://en.wikipedia.org/wiki/List_of_Warner_Bros._films_(2010%E2%80%932019)']\n",
    "list_movie_data = []\n",
    "for link in links:\n",
    "    page = requests.get(link)\n",
    "    content = bs(page.content, 'html.parser')\n",
    "    table_rows = content.select('.wikitable.sortable i')\n",
    "\n",
    "    #loop through table rows and scrape entry given the url\n",
    "    #Append movie info each iteration\n",
    "    for i,row in enumerate(table_rows):\n",
    "        if i % 10 == 0:\n",
    "            print(i);\n",
    "        try:\n",
    "            path = row.find('a')['href']\n",
    "            movie_url = 'https://en.wikipedia.org' + path\n",
    "            list_movie_data.append(scrape(movie_url))\n",
    "        except Exception as e:\n",
    "            print(movie_url)\n",
    "            print(e)\n",
    "    \n",
    "save_data('WB_movie_data.pickle', list_movie_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "02547280",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load movie data \n",
    "movie_data = load_data('WB_movie_data.pickle')\n",
    "#create pandas dataframe\n",
    "df = pd.DataFrame(movie_data)\n",
    "\n",
    "##dropping irrelevant columns\n",
    "for x in range(28):\n",
    "    df.drop(df.columns[26], axis=1, inplace = True)\n",
    "df.drop(df.columns[[5,6,7,18,20,21,22,24,25]], axis=1, inplace = True)\n",
    "df.to_csv('WB_movie_data_cleaned.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
